# Анализатор служебных переговоров


<h2 align="left">Анализатор служебных переговоров</h2>

<h2 align="left">Цели проекта.</h2>
<p align="left">В настоящий момент все служебные переговоры, связанные с движением поездов, фиксируются на регистратор переговоров и существует норматив у руководителей разных уровней по выборочному прослушиванию соблюдения регламента переговоров. Для этого необходимо прибыть к месту установки регистратора, т.к. аудиофайлы хранятся только на том регистраторе, который пишет конкретную линию связи. Это связано с большим отвлечением руководителей, и при этом имеет малую эффективность. Кроме этого, данная работа относится к категории рутинных. <p>

<h2 align="left">Технология распознование речи.</h2>
<p>
Whisper - это предварительно обученная модель для автоматического распознавания речи (ASR) и перевода речи. Обученная на 680 тысячах часов размеченных данных, модель Whisper демонстрирует высокую способность к обобщению на множество датасетов и доменов без необходимости дополнительного обучения.

Whisper была предложена в статье "Robust Speech Recognition via Large-Scale Weak Supervision" авторства Алека Рэдфорда и других сотрудников OpenAI. Оригинальный репозиторий кода можно найти здесь.

Whisper large-v3 имеет ту же архитектуру, что и предыдущие модели large, за исключением следующих незначительных различий:

Входные данные используют 128 мел-частотных бин вместо 80.
Новый языковой токен для кантонского языка.
Модель Whisper large-v3 обучена на 1 миллион часов слабо размеченного аудио и 4 миллиона часов псевдозначенного аудио, собранного с помощью Whisper large-v2. Модель была обучена на протяжении 2,0 эпох на этом смешанном датасете.</p>

<h2 align="left">Классификация переговоров на соответвие регламенту.</h2>
<p>
paraphrase-multilingual-MiniLM-L12-v2 - это модель от библиотеки sentence-transformers, предназначенная для парафразирования. Она преобразует предложения и абзацы в плотное векторное пространство размерностью 768 измерений, что позволяет использовать её для различных задач, таких как кластеризация или семантический поиск.

Модель 
paraphrase-multilingual-MiniLM-L12-v2 разработана для работы с несколькими языками и демонстрирует высокую эффективность в задачах, связанных с обработкой естественного языка (NLP). Векторное представление предложений и абзацев, создаваемое этой моделью, позволяет проводить более точные и релевантные поисковые запросы, а также улучшает качество кластеризации текстов на основе их семантического содержания.

Основные характеристики 
paraphrase-multilingual-MiniLM-L12-v2:

Многозадачность: Модель может обрабатывать тексты на различных языках, что делает её универсальным инструментом для многоязычных приложений.
Высокая точность: Благодаря использованию современных архитектур и методов обучения, модель обеспечивает высокую точность в задачах семантического поиска и кластеризации.
Эффективность: Векторное представление текстов позволяет значительно ускорить процесс поиска и анализа данных.
Эта модель особенно полезна для приложений, требующих глубокого понимания текста, таких как:

Поисковые системы: Улучшение релевантности результатов поиска.
Кластеризация документов: Группировка текстов на основе их семантической схожести.
Системы рекомендаций: Рекомендация контента, исходя из его семантической близости к предпочтениям пользователя.
Перевод и парафразирование: Создание более точных и релевантных переводов и перефразировок текста.
В целом, 
paraphrase-multilingual-MiniLM-L12-v2 является мощным инструментом для разработчиков и исследователей, занимающихся обработкой естественного языка и созданием многоязычных приложений.</p>

<h2 align="left">Анализатор возможных нарушений регламента.</h2>

<p>Qwen1.5 - это бета-версия модели Qwen2, представляющая собой языковую модель, основанную на архитектуре трансформера, с декодером и предобученную на большом объёме данных. В сравнении с предыдущей версией Qwen, улучшения включают:

8 размеров моделей, включая 0.5B, 1.8B, 4B, 7B, 14B, 32B и 72B плотных моделей, а также MoE модель с 14B параметрами и 2.7B активируемыми;
Значительное улучшение производительности в человеческих предпочтениях для моделей чата;
Многоязычная поддержка как базовых, так и чат-моделей;
Стабильная поддержка длины контекста до 32K для моделей всех размеров;
Отсутствие необходимости в trust_remote_code.
Для получения более подробной информации, пожалуйста, обратитесь к нашему блогу и репозиторию на GitHub.

Детали модели
Qwen1.5 - это серия языковых моделей, включающая декодирующие языковые модели различных размеров. Для каждого размера мы выпускаем базовую языковую модель и адаптированную чат-модель. Модель основана на архитектуре Transformer с активацией SwiGLU, смещением внимания QKV, групповым запросом внимания, сочетанием скользящего окна внимания и полного внимания и т.д. Кроме того, мы улучшили токенизатор, который адаптируется к различным естественным языкам и кодам. Для бета-версии временно не включены GQA (за исключением модели 32B) и комбинация SWA и полного внимания.</p>

<h2 align="left">КЛАССИФИКАТОР нарушений регламента служебных переговоров при поездной и маневровой работе</h2>

[![1-1.png](https://i.postimg.cc/zBPLyzjV/1-1.png)](https://postimg.cc/KkBcVyC2)
[![1-2.png](https://i.postimg.cc/dQpkv03f/1-2.png)](https://postimg.cc/9zPFYCGP)
[![1-3.png](https://i.postimg.cc/tgq7DZvs/1-3.png)](https://postimg.cc/75RxZ6k4)


## Работа с Backend приложением

Установка зависимостей
```shell script
pipenv install
pipenv shell
```

Применяем миграции БД
```sh
python manage.py migrate
```

Загрузка данных в БД
```sh
python manage.py load_data
python manage.py update_events_items
python manage.py create_users
```

Запускает dev-сервер
```sh
python manage.py runserver
```


## Работа с Frontend приложением

Установка зависимостей
```sh
cd front/mtsHack/
npm install
```

Запуск dev сервера
```sh
npm run dev
```

Сборка проекта
```sh
npm run build
```
